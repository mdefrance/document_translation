{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCR with DocTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import base64\n",
    "import re\n",
    "from tempfile import TemporaryDirectory\n",
    "from math import atan, cos, sin\n",
    "from typing import Dict, Optional, Tuple\n",
    "from xml.etree import ElementTree as ET\n",
    "from xml.etree.ElementTree import Element\n",
    "\n",
    "import numpy as np\n",
    "import PyPDF2\n",
    "from PyPDF2 import PdfFileMerger\n",
    "# from doctr.io import DocumentFile\n",
    "# from doctr.models import ocr_predictor\n",
    "from PIL import Image\n",
    "from reportlab.lib.colors import black\n",
    "from reportlab.lib.units import inch\n",
    "from reportlab.lib.utils import ImageReader\n",
    "from reportlab.pdfgen.canvas import Canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDF_PATH = '../DATA/'\n",
    "pdf_file = \"test.pdf\"\n",
    "file = '.'.join(pdf_file.split('.')[:-1])\n",
    "\n",
    "# getting array of RGB values from pdf file\n",
    "new_docs = pdf_to_array(PDF_PATH, pdf_file, zooming=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [new_docs[9], new_docs[10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "db_resnet50-adcafc63.zip\n",
    "crnn_vgg16_bn-76b7f2c6.zip\n",
    "crnn_mobilenet_v3_small-7f36edec.zip\n",
    "classif_mobilenet_v3_small-1ea8db03.zip\n",
    "\n",
    "mv db_resnet50-adcafc63.zip /home/jovyan/.cache/doctr/models/\n",
    "mv crnn_mobilenet_v3_small-7f36edec.zip /home/jovyan/.cache/doctr/models/\n",
    "mv classif_mobilenet_v3_small-1ea8db03.zip /home/jovyan/.cache/doctr/models/\n",
    "mv crnn_vgg16_bn-76b7f2c6.zip /home/jovyan/.cache/doctr/models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "from doctr.io import DocumentFile\n",
    "from doctr.utils.visualization import visualize_page\n",
    "from doctr.models import ocr_predictor\n",
    "\n",
    "WORK_PATH = '../DATA/WORK_OCR/'\n",
    "\n",
    "# loading docTR predictor\n",
    "model = ocr_predictor(det_arch='db_resnet50', reco_arch='crnn_vgg16_bn', pretrained=True)\n",
    "\n",
    "# # ocr of the pdf file\n",
    "xml_outputs = array_to_ocr_xml(new_docs, model)\n",
    "pickle.dump(xml_outputs, open(WORK_PATH+file+'_xml_outputs.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 0.05\n",
    "\n",
    "# ocr models prediction on each pages of the document\n",
    "ocred_docs = model(docs)\n",
    "\n",
    "# adding white spaces after each word\n",
    "for page in ocred_docs.pages:\n",
    "    for block in page.blocks:\n",
    "        for line in block.lines:\n",
    "            for word in line.words:\n",
    "                word.value += ' '\n",
    "                if word.confidence < thresh:\n",
    "                    word.value = ' '\n",
    "                print(word.value)\n",
    "\n",
    "# exporting to xml\n",
    "xml_outputs = ocred_docs.export_as_xml()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "PATH = '../DATA/'\n",
    "\n",
    "xml_outputs = pickle.load(open(WORK_PATH+file+'_xml_outputs.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: delete temporary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = '../DATA/PDFA/'\n",
    "pdfa_dict = xml_to_pdfa(SAVE_PATH, pdf_file, docs, xml_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the pdf file document \n",
    "doc = fitz.open(SAVE_PATH+file+'_pdfa.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = doc[0].get_textpage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(pdfa_dict, open(WORK_PATH+file+'.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../packages/')\n",
    "import os\n",
    "from HocrParser import HocrParser\n",
    "import fitz\n",
    "\n",
    "def pdf_to_array(PATH, file, zooming=3):\n",
    "    \"\"\" Converts pdf file to numpy array of RGB values.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "     - PATH, string: folder where to find .pdf file\n",
    "     - file, string: .pdf file name\n",
    "     - zooming, int, default 3: intensity of zooming x and y axes\n",
    "     \n",
    "    Returns\n",
    "    ----------\n",
    "     - doc_array, list(numpy.array): list of arrays of RGB uint8 for each page\n",
    "    \"\"\"\n",
    "    \n",
    "    # remove extension of file name\n",
    "    file_without_extension = '.'.join(file.split('.')[:-1])\n",
    "    \n",
    "    # opening the pdf file document \n",
    "    doc = fitz.open(PATH+file_without_extension+'.pdf')\n",
    "\n",
    "    # initiating arrays with scaling\n",
    "    image_matrix = fitz.Matrix(fitz.Identity)\n",
    "    image_matrix.preScale(zooming, zooming)\n",
    "\n",
    "    # getting pixels from each page of the document\n",
    "    doc_pixs = [page.getPixmap(alpha = False, matrix=image_matrix) for page in doc]\n",
    "\n",
    "    # converting pixels to an array of RGB (0 to 255) values for each page of the document\n",
    "    doc_array = [np.array(Image.frombytes('RGB', [pix.width, pix.height], pix.samples)) for pix in doc_pixs]\n",
    "\n",
    "    return doc_array\n",
    "\n",
    "\n",
    "\n",
    "def array_to_ocr_xml(docs, model, thresh=0.05):\n",
    "    \"\"\" Applies doctTR model on numpy array of RGB values.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "     - doc_array, list(numpy.array): list of arrays of RGB uint8 for each page\n",
    "     - model, ocr_predictor: ocr model from doctr.models\n",
    "     - thresh, float, default 0.05: confidence threshold for each word recognition\n",
    "     \n",
    "    Returns\n",
    "    ----------\n",
    "     - xml_outputs, list(tuple(string, xml.etree.ElementTree)): xml output from docTR\n",
    "    \"\"\"\n",
    "    \n",
    "    # ocr models prediction on each pages of the document\n",
    "    ocred_docs = model(docs)\n",
    "\n",
    "    # adding white spaces after each word\n",
    "    for page in ocred_docs.pages:\n",
    "        for block in page.blocks:\n",
    "            for line in block.lines:\n",
    "                for word in line.words:\n",
    "                    word.value += ' '\n",
    "                    if word.confidence < thresh:\n",
    "                        word.value = ' '\n",
    "    \n",
    "    # exporting to xml\n",
    "    xml_outputs = ocred_docs.export_as_xml()\n",
    "    \n",
    "    return xml_outputs\n",
    "\n",
    "def xml_to_pdfa(PATH, file, doc_array, xml_outputs):\n",
    "    \"\"\" Converts xml outputs from docTR to searchable PDF/A file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "     - PATH, string: folder where to save .pdf file\n",
    "     - file, string: .pdf file name\n",
    "     - doc_array, list(numpy.array): list of arrays of RGB uint8 for each page\n",
    "     - xml_outputs, list(tuple(string, xml.etree.ElementTree)): xml output from docTR\n",
    "     \n",
    "    Returns\n",
    "    ----------\n",
    "     - pdfa_dict, dict: dictionnary of int page number keys and string text value \n",
    "    \"\"\"    \n",
    "    \n",
    "    # remove extension of file name\n",
    "    file_without_extension = '.'.join(file.split('.')[:-1])\n",
    "    \n",
    "    # init parser\n",
    "    parser = HocrParser()\n",
    "    \n",
    "    # init merged pdf file\n",
    "    merger = PdfFileMerger()\n",
    "    \n",
    "    # iterate through the xml outputs and images and export to pdf/a\n",
    "    # the image is optional else you can set invisible_text=False and the text will be printed on a blank page\n",
    "    for i, (xml, img) in enumerate(zip(xml_outputs, doc_array)):\n",
    "        \n",
    "        # accessing xml.etree.ElementTree.ElementTree object\n",
    "        xml_element_tree = xml[1]\n",
    "        \n",
    "        # exporting the page to pdf/a file\n",
    "        parser.export_pdfa(f'{PATH+file_without_extension+str(i)}.pdf', hocr=xml_element_tree, image=img)\n",
    "        # adding the page to merged pdf/a file\n",
    "        merger.append(f'{PATH+file_without_extension+str(i)}.pdf')\n",
    "        \n",
    "    # saving merged pdf/a file\n",
    "    merger.write(f'{PATH+file_without_extension}.pdf')\n",
    "    \n",
    "    # accessing merged pdf/a file\n",
    "    pdfa_doc = fitz.open(f'{PATH+file_without_extension}.pdf')\n",
    "    \n",
    "    # converting pdf\n",
    "    pdfa_dict = {k:v.get_text() for k,v in enumerate(pdfa_doc)}\n",
    "    \n",
    "    return pdfa_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
