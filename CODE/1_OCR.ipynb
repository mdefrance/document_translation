{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives\n",
    "\n",
    "1. Applying Mindee's docTR Optical Character Recognition (OCR) to collect multiple PDFs' texts.\n",
    "\n",
    "2. Translating those texts using Meta AI's M2M-100.\n",
    "\n",
    "3. Building translated PDF/A documents (searchable PDFs).\n",
    "\n",
    "# Code\n",
    "\n",
    "## From .pdf to RGB arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting list of all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# paths where data is stored\n",
    "PDF_PATH = '../DATA/'\n",
    "PDFA_PATH = '../DATA/PDFA/'\n",
    "WORK_PATH = '../WORK/'\n",
    "\n",
    "# list of PDF files\n",
    "files = ['.'.join(f.split('.')[:-1]) for f in os.listdir(PDF_PATH) if f.endswith('.pdf')] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting to RGB numpy arrays:\n",
    "* Scaling (zoom)\n",
    "* Gray scaling\n",
    "* Deskewing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2028cb55f28348138809e168e6b713da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "func:'pdf_to_array' took: 21.8331 sec\n",
      "func:'pdf_to_array' took: 7.2664 sec\n",
      "func:'pdf_to_array' took: 17.1023 sec\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# scaling parameter to be applied to original PDF files\n",
    "zooming = 3 \n",
    "\n",
    "# iteration over each PDF file\n",
    "for file in tqdm(files):\n",
    "\n",
    "    # getting array of RGB values from pdf file (rotated for straight pages)\n",
    "    docs = pdf_to_array(PDF_PATH, file+'.pdf', zooming=zooming)\n",
    "    pickle.dump(docs, open(f'{WORK_PATH+file}_array.pkl','wb'))\n",
    "    # docs = pickle.load(open(f'{WORK_PATH+file}_array.pkl','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying OCR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Optical Character Recognition with mindee's docTR:\n",
    "\n",
    "https://mindee.github.io/doctr/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\envs\\doctr\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.7.0 and strictly below 2.10.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.6.5 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "from doctr.models import ocr_predictor\n",
    "\n",
    "# docTR pretrained models for rotated text \n",
    "# model = ocr_predictor(\n",
    "#     det_arch='linknet_resnet18_rotation', reco_arch='crnn_vgg16_bn', pretrained=True, \n",
    "#     assume_straight_pages=False, export_as_straight_boxes=True)\n",
    "\n",
    "# docTR pretrained models for straight text\n",
    "model = ocr_predictor(\n",
    "    det_arch='db_resnet50', reco_arch='crnn_vgg16_bn', pretrained=True, \n",
    "    assume_straight_pages=True, export_as_straight_boxes=True)\n",
    "\n",
    "# ocr of the pdf file\n",
    "xml_outputs = array_to_ocr_xml(docs, model)\n",
    "pickle.dump(xml_outputs, open(f'{WORK_PATH+file}_xml_outputs.pkl','wb'))\n",
    "# xml_outputs = pickle.load(open(f'{WORK_PATH+file}_xml_outputs.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting to PDFA file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "func:'xml_to_pdfa' took: 8.2860 sec\n"
     ]
    }
   ],
   "source": [
    "# building text and adding it to the original PDF file (image)\n",
    "pdfa_dict = xml_to_pdfa(PDFA_PATH, file+, docs, xml_outputs)\n",
    "pickle.dump(pdfa_dict, open(f'{WORK_PATH+file}_dict.pkl','wb'))\n",
    "# pdfa_dict = pickle.load(open(f'{WORK_PATH+file}_dict.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../packages/')\n",
    "import os\n",
    "from HocrParser import HocrParser\n",
    "import fitz\n",
    "import re\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from deskew import determine_skew\n",
    "\n",
    "from functools import wraps\n",
    "from time import time\n",
    "\n",
    "\n",
    "def timing(f):\n",
    "    @wraps(f)\n",
    "    def wrap(*args, **kw):\n",
    "        ts = time()\n",
    "        result = f(*args, **kw)\n",
    "        te = time()\n",
    "        print('func:%r took: %2.4f sec' % (f.__name__, te-ts))\n",
    "        return result\n",
    "    return wrap\n",
    "\n",
    "from random import sample\n",
    "import numpy\n",
    "from deskew import determine_skew\n",
    "\n",
    "def compute_doc_angle(docs, min_n_page=5, max_angle=5):\n",
    "    \"\"\" computes a documents text angle\"\"\"\n",
    "    \n",
    "    angles = []\n",
    "    retries=0\n",
    "    while (len(angles)<min_n_page) & (retries<2*min_n_page):\n",
    "        page = sample(docs, 1)[0]\n",
    "        angle = determine_skew(page)\n",
    "        if abs(angle)<max_angle:\n",
    "            angles += [angle]\n",
    "        retries+=1\n",
    "    \n",
    "    if retries>2*min_n_page:\n",
    "        angle = 0\n",
    "    else:\n",
    "        angle = numpy.median(angles)\n",
    "    \n",
    "    return angle\n",
    "\n",
    "def rotate_image(image, angle):\n",
    "    \"\"\" rotates a rgb image\"\"\"\n",
    "\n",
    "    # rotating image\n",
    "    (h, w) = image.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "    \n",
    "    return rotated\n",
    "\n",
    "def rotate_docs(docs, min_n_page=5, max_angle=5):\n",
    "    \"\"\" Rotates all pages of the document if needed.\"\"\"\n",
    "    \n",
    "    # computes median angle needed to straighten document\n",
    "    angle = compute_doc_angle(docs, min_n_page, max_angle)\n",
    "    \n",
    "    # if rotation is needed\n",
    "    if angle!=0:\n",
    "        \n",
    "        # rotates each pages\n",
    "        new_docs = []\n",
    "        for doc in docs:\n",
    "            new_docs += [rotate_image(doc, angle)]\n",
    "    \n",
    "    # else no rotation is needed, the initial images are returned\n",
    "    else:\n",
    "        new_docs = docs\n",
    "        \n",
    "    return new_docs\n",
    "\n",
    "@timing\n",
    "def pdf_to_array(PATH, file, zooming=3, min_n_page=5, max_angle=5):\n",
    "    \"\"\" Converts pdf file to numpy array of RGB values.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "     - PATH, string: folder where to find .pdf file\n",
    "     - file, string: .pdf file name\n",
    "     - zooming, int, default 3: intensity of zooming x and y axes\n",
    "     \n",
    "    Returns\n",
    "    ----------\n",
    "     - doc_array, list(numpy.array): list of arrays of RGB uint8 for each page\n",
    "    \"\"\"\n",
    "    \n",
    "    # remove extension of file name\n",
    "    file_without_extension = '.'.join(file.split('.')[:-1])\n",
    "    \n",
    "    # opening the pdf file document \n",
    "    doc = fitz.open(PATH+file_without_extension+'.pdf')\n",
    "\n",
    "    # initiating arrays with scaling\n",
    "    image_matrix = fitz.Matrix(fitz.Identity)\n",
    "    image_matrix.preScale(zooming, zooming)\n",
    "\n",
    "    # getting pixels from each page of the document\n",
    "    doc = [page.getPixmap(alpha = False, matrix=image_matrix) for page in doc]\n",
    "\n",
    "    # converting pixels to an array of RGB (0 to 255) values for each page of the document\n",
    "    doc = [np.array(Image.frombytes('RGB', [pix.width, pix.height], pix.samples)) for pix in doc]\n",
    "    \n",
    "    # rotating pages if needed\n",
    "    doc = rotate_docs(doc, min_n_page, max_angle)\n",
    "\n",
    "    return doc\n",
    "\n",
    "\n",
    "@timing\n",
    "def array_to_ocr_xml(docs, model, thresh=0.05):\n",
    "    \"\"\" Applies doctTR model on numpy array of RGB values.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "     - doc_array, list(numpy.array): list of arrays of RGB uint8 for each page\n",
    "     - model, ocr_predictor: ocr model from doctr.models\n",
    "     - thresh, float, default 0.05: confidence threshold for each word recognition\n",
    "     \n",
    "    Returns\n",
    "    ----------\n",
    "     - xml_outputs, list(tuple(string, xml.etree.ElementTree)): xml output from docTR\n",
    "    \"\"\"\n",
    "    \n",
    "    # ocr models prediction on each pages of the document\n",
    "    ocred_docs = model(docs)\n",
    "\n",
    "    # adding white spaces after each word\n",
    "    for page in ocred_docs.pages:\n",
    "        for block in page.blocks:\n",
    "            for line in block.lines:\n",
    "                for word in line.words:\n",
    "                    word.value += ' '\n",
    "                    if word.confidence < thresh:\n",
    "                        word.value = ' '\n",
    "    \n",
    "    # exporting to xml\n",
    "    xml_outputs = ocred_docs.export_as_xml()\n",
    "    \n",
    "    return xml_outputs\n",
    "\n",
    "@timing\n",
    "def xml_to_pdfa(PATH, file, doc_array, xml_outputs):\n",
    "    \"\"\" Converts xml outputs from docTR to searchable PDF/A file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "     - PATH, string: folder where to save .pdf file\n",
    "     - file, string: .pdf file name\n",
    "     - doc_array, list(numpy.array): list of arrays of RGB uint8 for each page\n",
    "     - xml_outputs, list(tuple(string, xml.etree.ElementTree)): xml output from docTR\n",
    "     \n",
    "    Returns\n",
    "    ----------\n",
    "     - pdfa_dict, dict: dictionnary of int page number keys and string text value \n",
    "    \"\"\"    \n",
    "    \n",
    "    # remove extension of file name\n",
    "    file_without_extension = '.'.join(file.split('.')[:-1])\n",
    "    \n",
    "    # init parser\n",
    "    parser = HocrParser()\n",
    "    \n",
    "    # init merged pdf file\n",
    "    merger = PdfFileMerger()\n",
    "    \n",
    "    # iterate through the xml outputs and images and export to pdf/a\n",
    "    # the image is optional else you can set invisible_text=False and the text will be printed on a blank page\n",
    "    for i, (xml, img) in enumerate(zip(xml_outputs, doc_array)):\n",
    "        \n",
    "        # accessing xml.etree.ElementTree.ElementTree object\n",
    "        xml_element_tree = xml[1]\n",
    "        \n",
    "        # exporting the page to pdf/a file\n",
    "        parser.export_pdfa(f'{PATH+file_without_extension+str(i)}.pdf', hocr=xml_element_tree, image=img)\n",
    "        # adding the page to merged pdf/a file\n",
    "        merger.append(f'{PATH+file_without_extension+str(i)}.pdf')\n",
    "        \n",
    "    # saving merged pdf/a file\n",
    "    merger.write(f'{PATH+file_without_extension}.pdf')\n",
    "    \n",
    "    # accessing merged pdf/a file\n",
    "    pdfa_doc = fitz.open(f'{PATH+file_without_extension}.pdf')\n",
    "    \n",
    "    # converting pdf\n",
    "    pdfa_dict = {k:v.get_text() for k,v in enumerate(pdfa_doc)}\n",
    "    \n",
    "    return pdfa_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
